---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Graphical Models, Regression Graphs, and Recursive Linear Regression in a Unified
  Way
subtitle: ''
summary: ''
authors:
- Marianna Bolla
- Fatma Abdelkhalek
- Máté Baranyi
tags:
- '"bayesian networks"'
- '"belief propagation"'
- '"decomposable models"'
- '"gaussian graphical models"'
- '"graphical models"'
- '"junction tree"'
- '"markov random fields"'
- '"regression graphs"'
categories: []
date: '2019-01-01'
lastmod: 2020-08-29T17:42:04+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-09-20T13:06:35.380012Z'
publication_types:
- '2'
abstract: This versatile topic goes back to the inventions of Gauss, Markov, and Gibbs,
  whose ideas are incorporated in graphical models and regression graphs. Later, the
  geneticist S. Wright (1923– 1934) and the philosopher and computer scientist J.
  Pearl (1986– 1987) developed the tools, but their notation is too complicated to
  formulate the mathematical background. Here we mainly follow the up-to-date discussion
  of statisticians S. Lauritzen and N. Wermuth, and try to juxtapose the directed–
  undirected and discrete– continuous cases.
publication: '*Acta Scientiarum Mathematicarum*'
doi: 10.14232/actasm-018-331-4
---
